{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import torchvision\n",
    "from torch import optim,nn\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder_hidden_layer = nn.Linear(\n",
    "            in_features=kwargs[\"input_shape\"], out_features=128\n",
    "        )\n",
    "        self.encoder_output_layer = nn.Linear(\n",
    "            in_features=128, out_features=128\n",
    "        )\n",
    "        self.decoder_hidden_layer = nn.Linear(\n",
    "            in_features=128, out_features=128\n",
    "        )\n",
    "        self.decoder_output_layer = nn.Linear(\n",
    "            in_features=128, out_features=kwargs[\"input_shape\"]\n",
    "        )\n",
    "\n",
    "    def forward(self, features):\n",
    "        activation = self.encoder_hidden_layer(features)\n",
    "        activation = torch.relu(activation)\n",
    "        code = self.encoder_output_layer(activation)\n",
    "        code = torch.relu(code)\n",
    "        activation = self.decoder_hidden_layer(code)\n",
    "        activation = torch.relu(activation)\n",
    "        activation = self.decoder_output_layer(activation)\n",
    "        reconstructed = torch.relu(activation)\n",
    "        return reconstructed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StanfordCars(Dataset):\n",
    "\n",
    "    def __init__(self, root: str, split: str = \"train\", transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self._split = split\n",
    "        self._base_folder = root\n",
    "\n",
    "        if self._split == \"train\":\n",
    "            self._images_base_path = self._base_folder + \"/train/\"\n",
    "        else:\n",
    "            self._images_base_path = self._base_folder + \"/test/\"\n",
    "\n",
    "        annotation = pd.DataFrame({\"Filename\":os.listdir(self._images_base_path)})\n",
    "\n",
    "        self._samples = [\n",
    "            (\n",
    "                str(self._images_base_path + annot),\n",
    "            )\n",
    "            for annot in annotation[\"Filename\"]\n",
    "        ]\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._samples)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"Returns pil_image and class_id for given index\"\"\"\n",
    "        image_path = self._samples[idx]\n",
    "        target = 0\n",
    "        \n",
    "        pil_image = Image.open(image_path[0]).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            pil_image = self.transform(pil_image)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return (pil_image, target)\n",
    "\n",
    "\n",
    "img_size = 288\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((img_size,img_size)),\n",
    "    #T.RandomResizedCrop(image_size), # data augmentation\n",
    "    # T.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor()])\n",
    "\n",
    "train_dataset = StanfordCars(root=\"/data/students/louis/standfordcars/standfordcars\",split =\"test\",transform=transform)\n",
    "\n",
    "test_dataset = StanfordCars(root=\"/data/students/louis/standfordcars/standfordcars\",split =\"train\",transform=transform)\n",
    "\n",
    "train_batch = 128\n",
    "train_loader = torch.utils.data.DataLoader( train_dataset, batch_size=train_batch, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(  test_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\",0)\n",
    "print(device)\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "model = AE(input_shape=img_size*img_size*3).to(device)\n",
    "\n",
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "restored_imgs = []\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for batch_features, _ in train_loader:\n",
    "        # reshape mini-batch data to [N, 784] matrix\n",
    "        # load it to the active device\n",
    "        batch_features = batch_features.view(-1, img_size*img_size*3).to(device)\n",
    "    \n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute reconstructions\n",
    "        outputs = model(batch_features)\n",
    "        \n",
    "        # compute training reconstruction loss\n",
    "        train_loss = criterion(outputs, batch_features)\n",
    "        \n",
    "        # compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss += train_loss.item()\n",
    "    \n",
    "    # compute the epoch training loss\n",
    "    loss = loss / len(train_loader)\n",
    "    losses.append(loss)\n",
    "    restored_imgs.append((epochs, batch_features, outputs))\n",
    " \n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "def imshowo(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# print images\n",
    "imshowo(torchvision.utils.make_grid(images))\n",
    "\n",
    "\n",
    "outputs = model(images.view(-1, img_size*img_size*3).to(device))\n",
    "rep = torch.Tensor.cpu(outputs).detach()\n",
    "# plt.imshow(rep.view(4*288,8*288,3))\n",
    "# plt.show()\n",
    "imshowo(torchvision.utils.make_grid(rep.view(32,3,288,288)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test_env2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0150bf111abbc7a6eeb7ff9bdbb989629e383a88937a1ab851ed76349f161389"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
